{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "# from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './input/fruits-360/Training'\n",
    "test_dir = './input/fruits-360/Test'\n",
    "\n",
    "np.random.seed(1234)\n",
    "directory=train_dir\n",
    "classes=[\"Apple Golden 1\",\"Avocado\",\"Banana\",\"Cherry 1\",\"Cocos\",\"Kiwi\",\n",
    "         \"Lemon\",\"Mango\",\"Orange\"]\n",
    "\n",
    "all_arrays=[]\n",
    "img_size=100\n",
    "for i in classes:\n",
    "    path=os.path.join(directory,i)\n",
    "    class_num=classes.index(i)\n",
    "    for img in os.listdir(path):\n",
    "        #img_array=cv2.imread(os.path.join(path,img),\n",
    "        #                     cv2.IMREAD_GRAYSCALE)\n",
    "        img_array=cv2.imread(os.path.join(path,img))\n",
    "        img_array=cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "        #img_array=cv2.resize(img_array,(img_size,img_size))\n",
    "        all_arrays.append([img_array,class_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory2=test_dir\n",
    "classes2=[\"Apple Golden 1\",\"Avocado\",\"Banana\",\"Cherry 1\",\"Cocos\",\"Kiwi\",\n",
    "         \"Lemon\",\"Mango\",\"Orange\"]\n",
    "\n",
    "all_arrays2=[]\n",
    "img_size=100\n",
    "for i in classes2:\n",
    "    path=os.path.join(directory2,i)\n",
    "    class_num2=classes2.index(i)\n",
    "    for img in os.listdir(path):\n",
    "        #img_array2=cv2.imread(os.path.join(path,img),\n",
    "        #                     cv2.IMREAD_GRAYSCALE)\n",
    "        img_array2=cv2.imread(os.path.join(path,img))\n",
    "        img_array2=cv2.cvtColor(img_array2, cv2.COLOR_BGR2RGB)\n",
    "        #img_array2=cv2.resize(img_array2,(img_size,img_size))\n",
    "        all_arrays2.append([img_array2,class_num2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = []\n",
    "\n",
    "for i in range(len(all_arrays)):\n",
    "    feature, label = all_arrays[i]\n",
    "    img = feature\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    kp, des = surf.detectAndCompute(img, None)\n",
    "\n",
    "    for d in des:\n",
    "        dico.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init 1/3 with method: k-means++\n",
      "Inertia for init 1/3: 5057.300209\n",
      "Init 2/3 with method: k-means++\n",
      "Inertia for init 2/3: 5014.246799\n",
      "Init 3/3 with method: k-means++\n",
      "Inertia for init 3/3: 5065.756911\n",
      "Minibatch iteration 1/500: mean batch inertia: 0.065431, ewa inertia: 0.065431 \n",
      "Minibatch iteration 2/500: mean batch inertia: 0.064659, ewa inertia: 0.065098 \n",
      "Minibatch iteration 3/500: mean batch inertia: 0.064231, ewa inertia: 0.064724 \n",
      "Minibatch iteration 4/500: mean batch inertia: 0.064221, ewa inertia: 0.064507 \n",
      "Minibatch iteration 5/500: mean batch inertia: 0.064415, ewa inertia: 0.064468 \n",
      "Minibatch iteration 6/500: mean batch inertia: 0.063672, ewa inertia: 0.064125 \n",
      "Minibatch iteration 7/500: mean batch inertia: 0.063871, ewa inertia: 0.064015 \n",
      "Minibatch iteration 8/500: mean batch inertia: 0.062797, ewa inertia: 0.063490 \n",
      "Minibatch iteration 9/500: mean batch inertia: 0.064115, ewa inertia: 0.063759 \n",
      "Minibatch iteration 10/500: mean batch inertia: 0.063968, ewa inertia: 0.063850 \n",
      "Minibatch iteration 11/500: mean batch inertia: 0.063347, ewa inertia: 0.063633 \n",
      "Minibatch iteration 12/500: mean batch inertia: 0.062688, ewa inertia: 0.063226 \n",
      "Minibatch iteration 13/500: mean batch inertia: 0.063700, ewa inertia: 0.063430 \n",
      "Minibatch iteration 14/500: mean batch inertia: 0.062925, ewa inertia: 0.063212 \n",
      "Minibatch iteration 15/500: mean batch inertia: 0.063513, ewa inertia: 0.063342 \n",
      "Minibatch iteration 16/500: mean batch inertia: 0.063120, ewa inertia: 0.063247 \n",
      "Minibatch iteration 17/500: mean batch inertia: 0.062501, ewa inertia: 0.062925 \n",
      "Minibatch iteration 18/500: mean batch inertia: 0.063486, ewa inertia: 0.063167 \n",
      "Minibatch iteration 19/500: mean batch inertia: 0.063562, ewa inertia: 0.063337 \n",
      "Minibatch iteration 20/500: mean batch inertia: 0.063016, ewa inertia: 0.063199 \n",
      "Minibatch iteration 21/500: mean batch inertia: 0.062871, ewa inertia: 0.063057 \n",
      "Minibatch iteration 22/500: mean batch inertia: 0.062508, ewa inertia: 0.062821 \n",
      "Minibatch iteration 23/500: mean batch inertia: 0.062926, ewa inertia: 0.062866 \n",
      "Minibatch iteration 24/500: mean batch inertia: 0.062923, ewa inertia: 0.062891 \n",
      "Minibatch iteration 25/500: mean batch inertia: 0.062713, ewa inertia: 0.062814 \n",
      "Minibatch iteration 26/500: mean batch inertia: 0.063348, ewa inertia: 0.063044 \n",
      "Minibatch iteration 27/500: mean batch inertia: 0.063183, ewa inertia: 0.063104 \n",
      "Minibatch iteration 28/500: mean batch inertia: 0.062732, ewa inertia: 0.062944 \n",
      "Minibatch iteration 29/500: mean batch inertia: 0.062994, ewa inertia: 0.062965 \n",
      "Minibatch iteration 30/500: mean batch inertia: 0.063232, ewa inertia: 0.063080 \n",
      "Minibatch iteration 31/500: mean batch inertia: 0.063195, ewa inertia: 0.063130 \n",
      "Minibatch iteration 32/500: mean batch inertia: 0.062040, ewa inertia: 0.062660 \n",
      "Minibatch iteration 33/500: mean batch inertia: 0.061906, ewa inertia: 0.062335 \n",
      "Minibatch iteration 34/500: mean batch inertia: 0.062424, ewa inertia: 0.062374 \n",
      "Minibatch iteration 35/500: mean batch inertia: 0.063367, ewa inertia: 0.062802 \n",
      "Minibatch iteration 36/500: mean batch inertia: 0.063221, ewa inertia: 0.062983 \n",
      "Minibatch iteration 37/500: mean batch inertia: 0.062974, ewa inertia: 0.062979 \n",
      "Minibatch iteration 38/500: mean batch inertia: 0.063443, ewa inertia: 0.063179 \n",
      "Minibatch iteration 39/500: mean batch inertia: 0.062979, ewa inertia: 0.063093 \n",
      "Minibatch iteration 40/500: mean batch inertia: 0.063143, ewa inertia: 0.063114 \n",
      "Minibatch iteration 41/500: mean batch inertia: 0.062154, ewa inertia: 0.062701 \n",
      "Minibatch iteration 42/500: mean batch inertia: 0.062371, ewa inertia: 0.062558 \n",
      "Minibatch iteration 43/500: mean batch inertia: 0.063036, ewa inertia: 0.062764 \n",
      "Converged (lack of improvement in inertia) at iteration 43/500\n",
      "Computing label assignment and total inertia\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "k = np.size(classes) * 10\n",
    "batch_size = np.size(all_arrays) * 3\n",
    "kmeans = MiniBatchKMeans(n_clusters=k, batch_size=batch_size, verbose=1).fit(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.verbose = False\n",
    "\n",
    "histo_list = []\n",
    "\n",
    "for i in range(len(all_arrays)):\n",
    "    feature, label = all_arrays[i]\n",
    "    img = feature\n",
    "    kp, des = surf.detectAndCompute(img, None)\n",
    "\n",
    "    histo = np.zeros(k)\n",
    "    nkp = np.size(kp)\n",
    "\n",
    "    for d in des:\n",
    "        idx = kmeans.predict([d])\n",
    "        histo[idx] += 1/nkp # Because we need normalized histograms, I prefere to add 1/nkp directly\n",
    "\n",
    "    histo_list.append(histo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.19418603\n",
      "Iteration 2, loss = 2.13235165\n",
      "Iteration 3, loss = 2.06697684\n",
      "Iteration 4, loss = 1.99080465\n",
      "Iteration 5, loss = 1.89948961\n",
      "Iteration 6, loss = 1.79485211\n",
      "Iteration 7, loss = 1.67954406\n",
      "Iteration 8, loss = 1.56094850\n",
      "Iteration 9, loss = 1.44415632\n",
      "Iteration 10, loss = 1.33283585\n",
      "Iteration 11, loss = 1.23041467\n",
      "Iteration 12, loss = 1.13684031\n",
      "Iteration 13, loss = 1.05386741\n",
      "Iteration 14, loss = 0.98074593\n",
      "Iteration 15, loss = 0.91562498\n",
      "Iteration 16, loss = 0.85883187\n",
      "Iteration 17, loss = 0.80896770\n",
      "Iteration 18, loss = 0.76502118\n",
      "Iteration 19, loss = 0.72525388\n",
      "Iteration 20, loss = 0.69012697\n",
      "Iteration 21, loss = 0.65870407\n",
      "Iteration 22, loss = 0.63017191\n",
      "Iteration 23, loss = 0.60375774\n",
      "Iteration 24, loss = 0.58039147\n",
      "Iteration 25, loss = 0.55850891\n",
      "Iteration 26, loss = 0.53846041\n",
      "Iteration 27, loss = 0.51990719\n",
      "Iteration 28, loss = 0.50270902\n",
      "Iteration 29, loss = 0.48682518\n",
      "Iteration 30, loss = 0.47179932\n",
      "Iteration 31, loss = 0.45805065\n",
      "Iteration 32, loss = 0.44557761\n",
      "Iteration 33, loss = 0.43341050\n",
      "Iteration 34, loss = 0.42193071\n",
      "Iteration 35, loss = 0.41075363\n",
      "Iteration 36, loss = 0.40053397\n",
      "Iteration 37, loss = 0.39094043\n",
      "Iteration 38, loss = 0.38176185\n",
      "Iteration 39, loss = 0.37290549\n",
      "Iteration 40, loss = 0.36461630\n",
      "Iteration 41, loss = 0.35710956\n",
      "Iteration 42, loss = 0.34983475\n",
      "Iteration 43, loss = 0.34243889\n",
      "Iteration 44, loss = 0.33533816\n",
      "Iteration 45, loss = 0.32924631\n",
      "Iteration 46, loss = 0.32312473\n",
      "Iteration 47, loss = 0.31737618\n",
      "Iteration 48, loss = 0.31175945\n",
      "Iteration 49, loss = 0.30646362\n",
      "Iteration 50, loss = 0.30103658\n",
      "Iteration 51, loss = 0.29649194\n",
      "Iteration 52, loss = 0.29154110\n",
      "Iteration 53, loss = 0.28685490\n",
      "Iteration 54, loss = 0.28226158\n",
      "Iteration 55, loss = 0.27806383\n",
      "Iteration 56, loss = 0.27434778\n",
      "Iteration 57, loss = 0.27040797\n",
      "Iteration 58, loss = 0.26672897\n",
      "Iteration 59, loss = 0.26361314\n",
      "Iteration 60, loss = 0.25984546\n",
      "Iteration 61, loss = 0.25654956\n",
      "Iteration 62, loss = 0.25316672\n",
      "Iteration 63, loss = 0.24997651\n",
      "Iteration 64, loss = 0.24699165\n",
      "Iteration 65, loss = 0.24425472\n",
      "Iteration 66, loss = 0.24115754\n",
      "Iteration 67, loss = 0.23897993\n",
      "Iteration 68, loss = 0.23607287\n",
      "Iteration 69, loss = 0.23348535\n",
      "Iteration 70, loss = 0.23104155\n",
      "Iteration 71, loss = 0.22859749\n",
      "Iteration 72, loss = 0.22684645\n",
      "Iteration 73, loss = 0.22497957\n",
      "Iteration 74, loss = 0.22188180\n",
      "Iteration 75, loss = 0.21958654\n",
      "Iteration 76, loss = 0.21792224\n",
      "Iteration 77, loss = 0.21552385\n",
      "Iteration 78, loss = 0.21375528\n",
      "Iteration 79, loss = 0.21221282\n",
      "Iteration 80, loss = 0.21009079\n",
      "Iteration 81, loss = 0.20823934\n",
      "Iteration 82, loss = 0.20630322\n",
      "Iteration 83, loss = 0.20424305\n",
      "Iteration 84, loss = 0.20275912\n",
      "Iteration 85, loss = 0.20131164\n",
      "Iteration 86, loss = 0.20005293\n",
      "Iteration 87, loss = 0.19812401\n",
      "Iteration 88, loss = 0.19672555\n",
      "Iteration 89, loss = 0.19501552\n",
      "Iteration 90, loss = 0.19342709\n",
      "Iteration 91, loss = 0.19208867\n",
      "Iteration 92, loss = 0.19069091\n",
      "Iteration 93, loss = 0.18928619\n",
      "Iteration 94, loss = 0.18809481\n",
      "Iteration 95, loss = 0.18641883\n",
      "Iteration 96, loss = 0.18567572\n",
      "Iteration 97, loss = 0.18396185\n",
      "Iteration 98, loss = 0.18278527\n",
      "Iteration 99, loss = 0.18133989\n",
      "Iteration 100, loss = 0.18025991\n",
      "Iteration 101, loss = 0.17946846\n",
      "Iteration 102, loss = 0.17782168\n",
      "Iteration 103, loss = 0.17685212\n",
      "Iteration 104, loss = 0.17562563\n",
      "Iteration 105, loss = 0.17524795\n",
      "Iteration 106, loss = 0.17345103\n",
      "Iteration 107, loss = 0.17201988\n",
      "Iteration 108, loss = 0.17093758\n",
      "Iteration 109, loss = 0.17010009\n",
      "Iteration 110, loss = 0.16923746\n",
      "Iteration 111, loss = 0.16846020\n",
      "Iteration 112, loss = 0.16715420\n",
      "Iteration 113, loss = 0.16633713\n",
      "Iteration 114, loss = 0.16517319\n",
      "Iteration 115, loss = 0.16416336\n",
      "Iteration 116, loss = 0.16293259\n",
      "Iteration 117, loss = 0.16210955\n",
      "Iteration 118, loss = 0.16117096\n",
      "Iteration 119, loss = 0.16009505\n",
      "Iteration 120, loss = 0.15924625\n",
      "Iteration 121, loss = 0.15811181\n",
      "Iteration 122, loss = 0.15754262\n",
      "Iteration 123, loss = 0.15686087\n",
      "Iteration 124, loss = 0.15550433\n",
      "Iteration 125, loss = 0.15501073\n",
      "Iteration 126, loss = 0.15425613\n",
      "Iteration 127, loss = 0.15359652\n",
      "Iteration 128, loss = 0.15223482\n",
      "Iteration 129, loss = 0.15125730\n",
      "Iteration 130, loss = 0.15041635\n",
      "Iteration 131, loss = 0.14973690\n",
      "Iteration 132, loss = 0.14877292\n",
      "Iteration 133, loss = 0.14827502\n",
      "Iteration 134, loss = 0.14732510\n",
      "Iteration 135, loss = 0.14674472\n",
      "Iteration 136, loss = 0.14537756\n",
      "Iteration 137, loss = 0.14494875\n",
      "Iteration 138, loss = 0.14392477\n",
      "Iteration 139, loss = 0.14337303\n",
      "Iteration 140, loss = 0.14255223\n",
      "Iteration 141, loss = 0.14215010\n",
      "Iteration 142, loss = 0.14090308\n",
      "Iteration 143, loss = 0.14027960\n",
      "Iteration 144, loss = 0.13953777\n",
      "Iteration 145, loss = 0.13866057\n",
      "Iteration 146, loss = 0.13836442\n",
      "Iteration 147, loss = 0.13757357\n",
      "Iteration 148, loss = 0.13679573\n",
      "Iteration 149, loss = 0.13593539\n",
      "Iteration 150, loss = 0.13540863\n",
      "Iteration 151, loss = 0.13452895\n",
      "Iteration 152, loss = 0.13401143\n",
      "Iteration 153, loss = 0.13301532\n",
      "Iteration 154, loss = 0.13276965\n",
      "Iteration 155, loss = 0.13177642\n",
      "Iteration 156, loss = 0.13147366\n",
      "Iteration 157, loss = 0.13036542\n",
      "Iteration 158, loss = 0.12991891\n",
      "Iteration 159, loss = 0.12929797\n",
      "Iteration 160, loss = 0.12867103\n",
      "Iteration 161, loss = 0.12816529\n",
      "Iteration 162, loss = 0.12762661\n",
      "Iteration 163, loss = 0.12657657\n",
      "Iteration 164, loss = 0.12602595\n",
      "Iteration 165, loss = 0.12551077\n",
      "Iteration 166, loss = 0.12476877\n",
      "Iteration 167, loss = 0.12410226\n",
      "Iteration 168, loss = 0.12352137\n",
      "Iteration 169, loss = 0.12313151\n",
      "Iteration 170, loss = 0.12253908\n",
      "Iteration 171, loss = 0.12226478\n",
      "Iteration 172, loss = 0.12149440\n",
      "Iteration 173, loss = 0.12066082\n",
      "Iteration 174, loss = 0.12046106\n",
      "Iteration 175, loss = 0.11938726\n",
      "Iteration 176, loss = 0.11922327\n",
      "Iteration 177, loss = 0.11850676\n",
      "Iteration 178, loss = 0.11816256\n",
      "Iteration 179, loss = 0.11750772\n",
      "Iteration 180, loss = 0.11676916\n",
      "Iteration 181, loss = 0.11610248\n",
      "Iteration 182, loss = 0.11560698\n",
      "Iteration 183, loss = 0.11522429\n",
      "Iteration 184, loss = 0.11448278\n",
      "Iteration 185, loss = 0.11406268\n",
      "Iteration 186, loss = 0.11354061\n",
      "Iteration 187, loss = 0.11335126\n",
      "Iteration 188, loss = 0.11265488\n",
      "Iteration 189, loss = 0.11196127\n",
      "Iteration 190, loss = 0.11177010\n",
      "Iteration 191, loss = 0.11107562\n",
      "Iteration 192, loss = 0.11067690\n",
      "Iteration 193, loss = 0.11003151\n",
      "Iteration 194, loss = 0.10998451\n",
      "Iteration 195, loss = 0.10903773\n",
      "Iteration 196, loss = 0.10865243\n",
      "Iteration 197, loss = 0.10841954\n",
      "Iteration 198, loss = 0.10782811\n",
      "Iteration 199, loss = 0.10727702\n",
      "Iteration 200, loss = 0.10661246\n",
      "Iteration 201, loss = 0.10599319\n",
      "Iteration 202, loss = 0.10558829\n",
      "Iteration 203, loss = 0.10531266\n",
      "Iteration 204, loss = 0.10468814\n",
      "Iteration 205, loss = 0.10417532\n",
      "Iteration 206, loss = 0.10380576\n",
      "Iteration 207, loss = 0.10329378\n",
      "Iteration 208, loss = 0.10265359\n",
      "Iteration 209, loss = 0.10249146\n",
      "Iteration 210, loss = 0.10234191\n",
      "Iteration 211, loss = 0.10192219\n",
      "Iteration 212, loss = 0.10098758\n",
      "Iteration 213, loss = 0.10077691\n",
      "Iteration 214, loss = 0.10035818\n",
      "Iteration 215, loss = 0.10003038\n",
      "Iteration 216, loss = 0.09936456\n",
      "Iteration 217, loss = 0.09893123\n",
      "Iteration 218, loss = 0.09851321\n",
      "Iteration 219, loss = 0.09818000\n",
      "Iteration 220, loss = 0.09760659\n",
      "Iteration 221, loss = 0.09725382\n",
      "Iteration 222, loss = 0.09674747\n",
      "Iteration 223, loss = 0.09670495\n",
      "Iteration 224, loss = 0.09583215\n",
      "Iteration 225, loss = 0.09555437\n",
      "Iteration 226, loss = 0.09512330\n",
      "Iteration 227, loss = 0.09473364\n",
      "Iteration 228, loss = 0.09451096\n",
      "Iteration 229, loss = 0.09418477\n",
      "Iteration 230, loss = 0.09382412\n",
      "Iteration 231, loss = 0.09296898\n",
      "Iteration 232, loss = 0.09309455\n",
      "Iteration 233, loss = 0.09253160\n",
      "Iteration 234, loss = 0.09185060\n",
      "Iteration 235, loss = 0.09201914\n",
      "Iteration 236, loss = 0.09109581\n",
      "Iteration 237, loss = 0.09081244\n",
      "Iteration 238, loss = 0.09020407\n",
      "Iteration 239, loss = 0.08973924\n",
      "Iteration 240, loss = 0.08966698\n",
      "Iteration 241, loss = 0.08965983\n",
      "Iteration 242, loss = 0.08912249\n",
      "Iteration 243, loss = 0.08852296\n",
      "Iteration 244, loss = 0.08804318\n",
      "Iteration 245, loss = 0.08769732\n",
      "Iteration 246, loss = 0.08713988\n",
      "Iteration 247, loss = 0.08697760\n",
      "Iteration 248, loss = 0.08665206\n",
      "Iteration 249, loss = 0.08606694\n",
      "Iteration 250, loss = 0.08599764\n",
      "Iteration 251, loss = 0.08565949\n",
      "Iteration 252, loss = 0.08535907\n",
      "Iteration 253, loss = 0.08494439\n",
      "Iteration 254, loss = 0.08454420\n",
      "Iteration 255, loss = 0.08396769\n",
      "Iteration 256, loss = 0.08384134\n",
      "Iteration 257, loss = 0.08337561\n",
      "Iteration 258, loss = 0.08293183\n",
      "Iteration 259, loss = 0.08257986\n",
      "Iteration 260, loss = 0.08220812\n",
      "Iteration 261, loss = 0.08184429\n",
      "Iteration 262, loss = 0.08170778\n",
      "Iteration 263, loss = 0.08105478\n",
      "Iteration 264, loss = 0.08081225\n",
      "Iteration 265, loss = 0.08072894\n",
      "Iteration 266, loss = 0.08021423\n",
      "Iteration 267, loss = 0.08000106\n",
      "Iteration 268, loss = 0.07958360\n",
      "Iteration 269, loss = 0.07922509\n",
      "Iteration 270, loss = 0.07891640\n",
      "Iteration 271, loss = 0.07858553\n",
      "Iteration 272, loss = 0.07817039\n",
      "Iteration 273, loss = 0.07779578\n",
      "Iteration 274, loss = 0.07761488\n",
      "Iteration 275, loss = 0.07729392\n",
      "Iteration 276, loss = 0.07688393\n",
      "Iteration 277, loss = 0.07668048\n",
      "Iteration 278, loss = 0.07609746\n",
      "Iteration 279, loss = 0.07621052\n",
      "Iteration 280, loss = 0.07595196\n",
      "Iteration 281, loss = 0.07541943\n",
      "Iteration 282, loss = 0.07501909\n",
      "Iteration 283, loss = 0.07492340\n",
      "Iteration 284, loss = 0.07435139\n",
      "Iteration 285, loss = 0.07398753\n",
      "Iteration 286, loss = 0.07393442\n",
      "Iteration 287, loss = 0.07344668\n",
      "Iteration 288, loss = 0.07324372\n",
      "Iteration 289, loss = 0.07277910\n",
      "Iteration 290, loss = 0.07266372\n",
      "Iteration 291, loss = 0.07221183\n",
      "Iteration 292, loss = 0.07247214\n",
      "Iteration 293, loss = 0.07165559\n",
      "Iteration 294, loss = 0.07143802\n",
      "Iteration 295, loss = 0.07134344\n",
      "Iteration 296, loss = 0.07074399\n",
      "Iteration 297, loss = 0.07071491\n",
      "Iteration 298, loss = 0.07033087\n",
      "Iteration 299, loss = 0.06992173\n",
      "Iteration 300, loss = 0.06972410\n",
      "Iteration 301, loss = 0.06960192\n",
      "Iteration 302, loss = 0.06911194\n",
      "Iteration 303, loss = 0.06882549\n",
      "Iteration 304, loss = 0.06837900\n",
      "Iteration 305, loss = 0.06844488\n",
      "Iteration 306, loss = 0.06805962\n",
      "Iteration 307, loss = 0.06772101\n",
      "Iteration 308, loss = 0.06748908\n",
      "Iteration 309, loss = 0.06687382\n",
      "Iteration 310, loss = 0.06700328\n",
      "Iteration 311, loss = 0.06666815\n",
      "Iteration 312, loss = 0.06665364\n",
      "Iteration 313, loss = 0.06634965\n",
      "Iteration 314, loss = 0.06582396\n",
      "Iteration 315, loss = 0.06554626\n",
      "Iteration 316, loss = 0.06526554\n",
      "Iteration 317, loss = 0.06498158\n",
      "Iteration 318, loss = 0.06482349\n",
      "Iteration 319, loss = 0.06443292\n",
      "Iteration 320, loss = 0.06420963\n",
      "Iteration 321, loss = 0.06441107\n",
      "Iteration 322, loss = 0.06475062\n",
      "Iteration 323, loss = 0.06387804\n",
      "Iteration 324, loss = 0.06344762\n",
      "Iteration 325, loss = 0.06310462\n",
      "Iteration 326, loss = 0.06275930\n",
      "Iteration 327, loss = 0.06248241\n",
      "Iteration 328, loss = 0.06207043\n",
      "Iteration 329, loss = 0.06184674\n",
      "Iteration 330, loss = 0.06171091\n",
      "Iteration 331, loss = 0.06137723\n",
      "Iteration 332, loss = 0.06153692\n",
      "Iteration 333, loss = 0.06098688\n",
      "Iteration 334, loss = 0.06077015\n",
      "Iteration 335, loss = 0.06051253\n",
      "Iteration 336, loss = 0.06010307\n",
      "Iteration 337, loss = 0.06000189\n",
      "Iteration 338, loss = 0.05960160\n",
      "Iteration 339, loss = 0.05939626\n",
      "Iteration 340, loss = 0.05922366\n",
      "Iteration 341, loss = 0.05906892\n",
      "Iteration 342, loss = 0.05910679\n",
      "Iteration 343, loss = 0.05879874\n",
      "Iteration 344, loss = 0.05816109\n",
      "Iteration 345, loss = 0.05825710\n",
      "Iteration 346, loss = 0.05832932\n",
      "Iteration 347, loss = 0.05786494\n",
      "Iteration 348, loss = 0.05757643\n",
      "Iteration 349, loss = 0.05715660\n",
      "Iteration 350, loss = 0.05674763\n",
      "Iteration 351, loss = 0.05687593\n",
      "Iteration 352, loss = 0.05632277\n",
      "Iteration 353, loss = 0.05623851\n",
      "Iteration 354, loss = 0.05591098\n",
      "Iteration 355, loss = 0.05570750\n",
      "Iteration 356, loss = 0.05556793\n",
      "Iteration 357, loss = 0.05538996\n",
      "Iteration 358, loss = 0.05543209\n",
      "Iteration 359, loss = 0.05496217\n",
      "Iteration 360, loss = 0.05470521\n",
      "Iteration 361, loss = 0.05460112\n",
      "Iteration 362, loss = 0.05424734\n",
      "Iteration 363, loss = 0.05404209\n",
      "Iteration 364, loss = 0.05380009\n",
      "Iteration 365, loss = 0.05376851\n",
      "Iteration 366, loss = 0.05349431\n",
      "Iteration 367, loss = 0.05341732\n",
      "Iteration 368, loss = 0.05288290\n",
      "Iteration 369, loss = 0.05285322\n",
      "Iteration 370, loss = 0.05271161\n",
      "Iteration 371, loss = 0.05227556\n",
      "Iteration 372, loss = 0.05232424\n",
      "Iteration 373, loss = 0.05227719\n",
      "Iteration 374, loss = 0.05187367\n",
      "Iteration 375, loss = 0.05159150\n",
      "Iteration 376, loss = 0.05127636\n",
      "Iteration 377, loss = 0.05110167\n",
      "Iteration 378, loss = 0.05099082\n",
      "Iteration 379, loss = 0.05069601\n",
      "Iteration 380, loss = 0.05050246\n",
      "Iteration 381, loss = 0.05056691\n",
      "Iteration 382, loss = 0.05008856\n",
      "Iteration 383, loss = 0.04991015\n",
      "Iteration 384, loss = 0.05010271\n",
      "Iteration 385, loss = 0.04966690\n",
      "Iteration 386, loss = 0.04937204\n",
      "Iteration 387, loss = 0.04939014\n",
      "Iteration 388, loss = 0.04894921\n",
      "Iteration 389, loss = 0.04867475\n",
      "Iteration 390, loss = 0.04866819\n",
      "Iteration 391, loss = 0.04828049\n",
      "Iteration 392, loss = 0.04840688\n",
      "Iteration 393, loss = 0.04811346\n",
      "Iteration 394, loss = 0.04807086\n",
      "Iteration 395, loss = 0.04766359\n",
      "Iteration 396, loss = 0.04731957\n",
      "Iteration 397, loss = 0.04725960\n",
      "Iteration 398, loss = 0.04726365\n",
      "Iteration 399, loss = 0.04706968\n",
      "Iteration 400, loss = 0.04664753\n",
      "Iteration 401, loss = 0.04672869\n",
      "Iteration 402, loss = 0.04650461\n",
      "Iteration 403, loss = 0.04601767\n",
      "Iteration 404, loss = 0.04599385\n",
      "Iteration 405, loss = 0.04575785\n",
      "Iteration 406, loss = 0.04574592\n",
      "Iteration 407, loss = 0.04552046\n",
      "Iteration 408, loss = 0.04517773\n",
      "Iteration 409, loss = 0.04521626\n",
      "Iteration 410, loss = 0.04484251\n",
      "Iteration 411, loss = 0.04485027\n",
      "Iteration 412, loss = 0.04468311\n",
      "Iteration 413, loss = 0.04428482\n",
      "Iteration 414, loss = 0.04426073\n",
      "Iteration 415, loss = 0.04407253\n",
      "Iteration 416, loss = 0.04386316\n",
      "Iteration 417, loss = 0.04378791\n",
      "Iteration 418, loss = 0.04357900\n",
      "Iteration 419, loss = 0.04344971\n",
      "Iteration 420, loss = 0.04309295\n",
      "Iteration 421, loss = 0.04318889\n",
      "Iteration 422, loss = 0.04281734\n",
      "Iteration 423, loss = 0.04267356\n",
      "Iteration 424, loss = 0.04243797\n",
      "Iteration 425, loss = 0.04226459\n",
      "Iteration 426, loss = 0.04224825\n",
      "Iteration 427, loss = 0.04202133\n",
      "Iteration 428, loss = 0.04188291\n",
      "Iteration 429, loss = 0.04173016\n",
      "Iteration 430, loss = 0.04152206\n",
      "Iteration 431, loss = 0.04144011\n",
      "Iteration 432, loss = 0.04129240\n",
      "Iteration 433, loss = 0.04105693\n",
      "Iteration 434, loss = 0.04090761\n",
      "Iteration 435, loss = 0.04095980\n",
      "Iteration 436, loss = 0.04060446\n",
      "Iteration 437, loss = 0.04034965\n",
      "Iteration 438, loss = 0.04025303\n",
      "Iteration 439, loss = 0.04032303\n",
      "Iteration 440, loss = 0.04002411\n",
      "Iteration 441, loss = 0.03983465\n",
      "Iteration 442, loss = 0.03963223\n",
      "Iteration 443, loss = 0.03981262\n",
      "Iteration 444, loss = 0.03957993\n",
      "Iteration 445, loss = 0.03921662\n",
      "Iteration 446, loss = 0.03905143\n",
      "Iteration 447, loss = 0.03892315\n",
      "Iteration 448, loss = 0.03865131\n",
      "Iteration 449, loss = 0.03866090\n",
      "Iteration 450, loss = 0.03864853\n",
      "Iteration 451, loss = 0.03846694\n",
      "Iteration 452, loss = 0.03818610\n",
      "Iteration 453, loss = 0.03802160\n",
      "Iteration 454, loss = 0.03778516\n",
      "Iteration 455, loss = 0.03764182\n",
      "Iteration 456, loss = 0.03756887\n",
      "Iteration 457, loss = 0.03747051\n",
      "Iteration 458, loss = 0.03736062\n",
      "Iteration 459, loss = 0.03702799\n",
      "Iteration 460, loss = 0.03699425\n",
      "Iteration 461, loss = 0.03700825\n",
      "Iteration 462, loss = 0.03675726\n",
      "Iteration 463, loss = 0.03653573\n",
      "Iteration 464, loss = 0.03640435\n",
      "Iteration 465, loss = 0.03622185\n",
      "Iteration 466, loss = 0.03630147\n",
      "Iteration 467, loss = 0.03613351\n",
      "Iteration 468, loss = 0.03585442\n",
      "Iteration 469, loss = 0.03590332\n",
      "Iteration 470, loss = 0.03580079\n",
      "Iteration 471, loss = 0.03561303\n",
      "Iteration 472, loss = 0.03526313\n",
      "Iteration 473, loss = 0.03530191\n",
      "Iteration 474, loss = 0.03507980\n",
      "Iteration 475, loss = 0.03483858\n",
      "Iteration 476, loss = 0.03492104\n",
      "Iteration 477, loss = 0.03464694\n",
      "Iteration 478, loss = 0.03476140\n",
      "Iteration 479, loss = 0.03439664\n",
      "Iteration 480, loss = 0.03417096\n",
      "Iteration 481, loss = 0.03402713\n",
      "Iteration 482, loss = 0.03382738\n",
      "Iteration 483, loss = 0.03379964\n",
      "Iteration 484, loss = 0.03364013\n",
      "Iteration 485, loss = 0.03339239\n",
      "Iteration 486, loss = 0.03351897\n",
      "Iteration 487, loss = 0.03345412\n",
      "Iteration 488, loss = 0.03316226\n",
      "Iteration 489, loss = 0.03290976\n",
      "Iteration 490, loss = 0.03302710\n",
      "Iteration 491, loss = 0.03290370\n",
      "Iteration 492, loss = 0.03265241\n",
      "Iteration 493, loss = 0.03250849\n",
      "Iteration 494, loss = 0.03251586\n",
      "Iteration 495, loss = 0.03218382\n",
      "Iteration 496, loss = 0.03203783\n",
      "Iteration 497, loss = 0.03196637\n",
      "Iteration 498, loss = 0.03199379\n",
      "Iteration 499, loss = 0.03177201\n",
      "Iteration 500, loss = 0.03164326\n",
      "Iteration 501, loss = 0.03147975\n",
      "Iteration 502, loss = 0.03136718\n",
      "Iteration 503, loss = 0.03117804\n",
      "Iteration 504, loss = 0.03122565\n",
      "Iteration 505, loss = 0.03098642\n",
      "Iteration 506, loss = 0.03084588\n",
      "Iteration 507, loss = 0.03065730\n",
      "Iteration 508, loss = 0.03104174\n",
      "Iteration 509, loss = 0.03047891\n",
      "Iteration 510, loss = 0.03039218\n",
      "Iteration 511, loss = 0.03036052\n",
      "Iteration 512, loss = 0.03026755\n",
      "Iteration 513, loss = 0.03013905\n",
      "Iteration 514, loss = 0.02992814\n",
      "Iteration 515, loss = 0.02982736\n",
      "Iteration 516, loss = 0.02970387\n",
      "Iteration 517, loss = 0.02963136\n",
      "Iteration 518, loss = 0.02940157\n",
      "Iteration 519, loss = 0.02933592\n",
      "Iteration 520, loss = 0.02918954\n",
      "Iteration 521, loss = 0.02900627\n",
      "Iteration 522, loss = 0.02906035\n",
      "Iteration 523, loss = 0.02897096\n",
      "Iteration 524, loss = 0.02878695\n",
      "Iteration 525, loss = 0.02861477\n",
      "Iteration 526, loss = 0.02852120\n",
      "Iteration 527, loss = 0.02836048\n",
      "Iteration 528, loss = 0.02835888\n",
      "Iteration 529, loss = 0.02820738\n",
      "Iteration 530, loss = 0.02807037\n",
      "Iteration 531, loss = 0.02797474\n",
      "Iteration 532, loss = 0.02808909\n",
      "Iteration 533, loss = 0.02786562\n",
      "Iteration 534, loss = 0.02764242\n",
      "Iteration 535, loss = 0.02752748\n",
      "Iteration 536, loss = 0.02728754\n",
      "Iteration 537, loss = 0.02719488\n",
      "Iteration 538, loss = 0.02724119\n",
      "Iteration 539, loss = 0.02728304\n",
      "Iteration 540, loss = 0.02707686\n",
      "Iteration 541, loss = 0.02678424\n",
      "Iteration 542, loss = 0.02664871\n",
      "Iteration 543, loss = 0.02687590\n",
      "Iteration 544, loss = 0.02654204\n",
      "Iteration 545, loss = 0.02653194\n",
      "Iteration 546, loss = 0.02654347\n",
      "Iteration 547, loss = 0.02619372\n",
      "Iteration 548, loss = 0.02607010\n",
      "Iteration 549, loss = 0.02595717\n",
      "Iteration 550, loss = 0.02590231\n",
      "Iteration 551, loss = 0.02571340\n",
      "Iteration 552, loss = 0.02565845\n",
      "Iteration 553, loss = 0.02553829\n",
      "Iteration 554, loss = 0.02571384\n",
      "Iteration 555, loss = 0.02546581\n",
      "Iteration 556, loss = 0.02532340\n",
      "Iteration 557, loss = 0.02507388\n",
      "Iteration 558, loss = 0.02505752\n",
      "Iteration 559, loss = 0.02497602\n",
      "Iteration 560, loss = 0.02488791\n",
      "Iteration 561, loss = 0.02466765\n",
      "Iteration 562, loss = 0.02467622\n",
      "Iteration 563, loss = 0.02461184\n",
      "Iteration 564, loss = 0.02438538\n",
      "Iteration 565, loss = 0.02431718\n",
      "Iteration 566, loss = 0.02432474\n",
      "Iteration 567, loss = 0.02413154\n",
      "Iteration 568, loss = 0.02420415\n",
      "Iteration 569, loss = 0.02400992\n",
      "Iteration 570, loss = 0.02390854\n",
      "Iteration 571, loss = 0.02389638\n",
      "Iteration 572, loss = 0.02373561\n",
      "Iteration 573, loss = 0.02357840\n",
      "Iteration 574, loss = 0.02356786\n",
      "Iteration 575, loss = 0.02335556\n",
      "Iteration 576, loss = 0.02336421\n",
      "Iteration 577, loss = 0.02326311\n",
      "Iteration 578, loss = 0.02319514\n",
      "Iteration 579, loss = 0.02309164\n",
      "Iteration 580, loss = 0.02304967\n",
      "Iteration 581, loss = 0.02302445\n",
      "Iteration 582, loss = 0.02272145\n",
      "Iteration 583, loss = 0.02263827\n",
      "Iteration 584, loss = 0.02258055\n",
      "Iteration 585, loss = 0.02243782\n",
      "Iteration 586, loss = 0.02231458\n",
      "Iteration 587, loss = 0.02224381\n",
      "Iteration 588, loss = 0.02243059\n",
      "Iteration 589, loss = 0.02209818\n",
      "Iteration 590, loss = 0.02206710\n",
      "Iteration 591, loss = 0.02199110\n",
      "Iteration 592, loss = 0.02194107\n",
      "Iteration 593, loss = 0.02165488\n",
      "Iteration 594, loss = 0.02186101\n",
      "Iteration 595, loss = 0.02167199\n",
      "Iteration 596, loss = 0.02139329\n",
      "Iteration 597, loss = 0.02140957\n",
      "Iteration 598, loss = 0.02120539\n",
      "Iteration 599, loss = 0.02114889\n",
      "Iteration 600, loss = 0.02107316\n",
      "Iteration 601, loss = 0.02092886\n",
      "Iteration 602, loss = 0.02094730\n",
      "Iteration 603, loss = 0.02090492\n",
      "Iteration 604, loss = 0.02079816\n",
      "Iteration 605, loss = 0.02070538\n",
      "Iteration 606, loss = 0.02053125\n",
      "Iteration 607, loss = 0.02043595\n",
      "Iteration 608, loss = 0.02039073\n",
      "Iteration 609, loss = 0.02044182\n",
      "Iteration 610, loss = 0.02015765\n",
      "Iteration 611, loss = 0.02009235\n",
      "Iteration 612, loss = 0.02006850\n",
      "Iteration 613, loss = 0.01993753\n",
      "Iteration 614, loss = 0.01989870\n",
      "Iteration 615, loss = 0.01993507\n",
      "Iteration 616, loss = 0.01985062\n",
      "Iteration 617, loss = 0.01980880\n",
      "Iteration 618, loss = 0.01959234\n",
      "Iteration 619, loss = 0.01951708\n",
      "Iteration 620, loss = 0.01944105\n",
      "Iteration 621, loss = 0.01925522\n",
      "Iteration 622, loss = 0.01920709\n",
      "Iteration 623, loss = 0.01919044\n",
      "Iteration 624, loss = 0.01917340\n",
      "Iteration 625, loss = 0.01927488\n",
      "Iteration 626, loss = 0.01890904\n",
      "Iteration 627, loss = 0.01888252\n",
      "Iteration 628, loss = 0.01879179\n",
      "Iteration 629, loss = 0.01881639\n",
      "Iteration 630, loss = 0.01868114\n",
      "Iteration 631, loss = 0.01853578\n",
      "Iteration 632, loss = 0.01856890\n",
      "Iteration 633, loss = 0.01848467\n",
      "Iteration 634, loss = 0.01837203\n",
      "Iteration 635, loss = 0.01823931\n",
      "Iteration 636, loss = 0.01819404\n",
      "Iteration 637, loss = 0.01806789\n",
      "Iteration 638, loss = 0.01799497\n",
      "Iteration 639, loss = 0.01792812\n",
      "Iteration 640, loss = 0.01787329\n",
      "Iteration 641, loss = 0.01782980\n",
      "Iteration 642, loss = 0.01777009\n",
      "Iteration 643, loss = 0.01769550\n",
      "Iteration 644, loss = 0.01768276\n",
      "Iteration 645, loss = 0.01758552\n",
      "Iteration 646, loss = 0.01753539\n",
      "Iteration 647, loss = 0.01744863\n",
      "Iteration 648, loss = 0.01736905\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=600000, verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = np.array(histo_list)\n",
    "Y = []\n",
    "\n",
    "# It's a way to convert species name into an integer\n",
    "for feature,s in all_arrays:\n",
    "    Y.append(s)\n",
    "\n",
    "mlp = MLPClassifier(verbose=True, max_iter=600000)\n",
    "mlp.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "result_file = open(\"surf.csv\", \"w\")\n",
    "result_file_obj = csv.writer(result_file)\n",
    "result_file_obj.writerow(np.append(\"img\", 'class'))\n",
    "\n",
    "for i in range(len(all_arrays2)):\n",
    "    feature, label = all_arrays2[i]\n",
    "    img = feature\n",
    "    kp, des = surf.detectAndCompute(img, None)\n",
    "\n",
    "    x = np.zeros(k)\n",
    "    nkp = np.size(kp)\n",
    "\n",
    "    for d in des:\n",
    "        idx = kmeans.predict([d])\n",
    "        x[idx] += 1/nkp\n",
    "\n",
    "    res = mlp.predict([x])\n",
    "    row = []\n",
    "    row.append(i)\n",
    "\n",
    "#     for e in res[0]:\n",
    "#         row.append(e)\n",
    "\n",
    "    row.append(res[0])\n",
    "\n",
    "    result_file_obj.writerow(row)\n",
    "\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "X = np.array(histo_list)\n",
    "Y = []\n",
    "\n",
    "for feature,s in all_arrays:\n",
    "    Y.append(s)\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "result_file = open(\"surf_svm.csv\", \"w\")\n",
    "result_file_obj = csv.writer(result_file)\n",
    "result_file_obj.writerow(np.append(\"img\", 'class'))\n",
    "\n",
    "for i in range(len(all_arrays2)):\n",
    "    feature, label = all_arrays2[i]\n",
    "    img = feature\n",
    "    kp, des = surf.detectAndCompute(img, None)\n",
    "\n",
    "    x = np.zeros(k)\n",
    "    nkp = np.size(kp)\n",
    "\n",
    "    for d in des:\n",
    "        idx = kmeans.predict([d])\n",
    "        x[idx] += 1/nkp\n",
    "\n",
    "    res = svm.predict([x])\n",
    "    row = []\n",
    "    row.append(i)\n",
    "\n",
    "#     for e in res[0]:\n",
    "#         row.append(e)\n",
    "\n",
    "    row.append(res[0])\n",
    "\n",
    "    result_file_obj.writerow(row)\n",
    "\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1440</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1441</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1442</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1443</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1444</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1445 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       img  class\n",
       "0        0      0\n",
       "1        1      0\n",
       "2        2      0\n",
       "3        3      0\n",
       "4        4      0\n",
       "...    ...    ...\n",
       "1440  1440      8\n",
       "1441  1441      8\n",
       "1442  1442      8\n",
       "1443  1443      8\n",
       "1444  1444      8\n",
       "\n",
       "[1445 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res = pd.read_csv('./surf_svm.csv')\n",
    "svm_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "for feature, label in all_arrays2:\n",
    "    y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_res['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8532871972318339\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Apple Golden 1       1.00      1.00      1.00       160\n",
      "       Avocado       0.85      0.65      0.74       143\n",
      "        Banana       0.97      0.99      0.98       166\n",
      "      Cherry 1       0.99      0.97      0.98       164\n",
      "         Cocos       0.84      0.76      0.80       166\n",
      "          Kiwi       0.59      0.81      0.69       156\n",
      "         Lemon       0.85      0.85      0.85       164\n",
      "         Mango       0.83      0.72      0.77       166\n",
      "        Orange       0.84      0.90      0.87       160\n",
      "\n",
      "      accuracy                           0.85      1445\n",
      "     macro avg       0.86      0.85      0.85      1445\n",
      "  weighted avg       0.86      0.85      0.85      1445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=[\"Apple Golden 1\",\"Avocado\",\"Banana\",\"Cherry 1\",\"Cocos\",\"Kiwi\",\n",
    "         \"Lemon\",\"Mango\",\"Orange\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SURF + SVM: 85.33%\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "#compute conf mat\n",
    "conf_mat=confusion_matrix(y_test,y_pred)\n",
    "#plot the con mat\n",
    "fruit_names=[\"Apple\",\"Avocado\",\"Banana\",\"Cherry\",\"Cocos\",\"Kiwi\",\"Lemon\",\"Mango\",\"Orange\"]\n",
    "f,ax=plt.subplots(figsize=(10,9))\n",
    "sns.heatmap(conf_mat,annot=True,fmt='.0f')\n",
    "ax.set_xticklabels(fruit_names)\n",
    "ax.set_yticklabels(fruit_names)\n",
    "plt.show()\n",
    "precision = metrics.accuracy_score(y_test, y_pred) * 100\n",
    "print(\"Accuracy with SURF + SVM: {0:.2f}%\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
